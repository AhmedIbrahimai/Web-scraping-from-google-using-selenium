{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\amb\\Downloads\")\n",
    "#os.chdir(r\"C:\\Users\\amb\\Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5686\n",
      "11524\n",
      "17346\n",
      "23418\n",
      "23499\n",
      "23499\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\amb\\Downloads\")\n",
    "#os.chdir(r\"C:\\Users\\amb\\Downloads\n",
    "\n",
    "from selenium import webdriver\n",
    "import time as t\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import urllib\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"dataset_download\")    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "#try:\n",
    "  #  os.mkdir(\"dataset_crop\")    \n",
    "#except:\n",
    "  #  pass\n",
    "\n",
    "\n",
    "name=\"tongue out\"\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions() \n",
    "\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", ['enable-automation'])\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='chromedriver.exe',options=chrome_options)  \n",
    "\n",
    "strr=\"https://www.google.com/search?q=tongue+out&tbm=isch&ved=2ahUKEwjuzuebo6zzAhVI-4UKHYjeBp4Q2-cCegQIABAA&oq=tongue+out&gs_lcp=CgNpbWcQAzIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQ6CQgAEIAEEAoQAToICAAQChABEBg6BggAEAoQGDoECAAQQzoECAAQCjoICAAQgAQQsQM6CwgAEIAEELEDEIMBOgoIIxDvAxDqAhAnOgcIIxDvAxAnOgcIABCxAxBDUKHmA1jYtwRgibwEaARwAHgDgAHZBogBiyySAQ0xLjUuMS4xLjEuNS4xmAEAoAEBqgELZ3dzLXdpei1pbWewAQrAAQE&sclient=img&ei=-ZlYYa7uKMj2lwSIvZvwCQ&bih=788&biw=1600\"\n",
    "\n",
    "driver.get(strr)\n",
    "t.sleep(3)\n",
    "\n",
    "pics=driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]')\n",
    "\n",
    "links=[]\n",
    "x=1\n",
    "last_height=0\n",
    "\n",
    "def download_image(url,filename):\n",
    "    resource = urllib.request.urlopen(url)\n",
    "    output = open(filename,\"wb\")\n",
    "    output.write(resource.read())\n",
    "    output.close()\n",
    "    \n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    t.sleep(4)\n",
    "    pics_=pics.find_elements_by_xpath('./*')# //*[@id=\"islrg\"]/div[1]/div[1]\n",
    "    \n",
    "    for pic in pics_:\n",
    "        try:\n",
    "            img_link=pic.find_element_by_xpath('a[1]/div[1]/img').get_attribute('src') \n",
    "            \n",
    "            if img_link not in links:\n",
    "                links.append(img_link)\n",
    "                try:\n",
    "                    os.mkdir('dataset_download//'+name)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    os.mkdir('dataset_crop//'+name)\n",
    "                except:\n",
    "                    pass\n",
    "                file_name='dataset_download//'+name+'//'+str(x)+'.jpg'\n",
    "                download_image(img_link,file_name)\n",
    "                \n",
    "                x+=1\n",
    "        except:\n",
    "            print('-',end='')\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    print(new_height)\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "        \n",
    "        \n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\amb\\\\Downloads'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 171 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027573DBFD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002757527CEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1 2 3 4 pics//Ahmed\\Adèle_Haenel_Cannes_2016.jpg\n",
      "5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 pics//Ahmed\\المرأة-غمز-ب-عين-واحد-ألبوم-الصور__k9849509.jpg\n"
     ]
    }
   ],
   "source": [
    "import mtcnn\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"C:/Users/amb/Downloads/dataset_download\")\n",
    "\n",
    "name=\"Ahmed\"\n",
    "\n",
    "try:\n",
    "    os.mkdir('faces dataset//'+name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "detector=mtcnn.MTCNN()\n",
    "#cap=cv2.VideoCapture(0)\n",
    "imgs=glob.glob(f'pics//{name}//*.jpg')\n",
    "l=0\n",
    "for img_d in imgs:\n",
    "    try:\n",
    "        img=cv2.imread(img_d)\n",
    "        faces=detector.detect_faces(img)\n",
    "        try:\n",
    "            for f in faces:\n",
    "                faces=cv2.resize(f,(224,224))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for face in faces:\n",
    "            x,y,w,h=face['box']\n",
    "            roi=img[y:y+h,x:x+w]\n",
    "            cv2.imwrite(\"faces dataset//\"+name+\"//\"+name+\"_\"+str(l)+\".jpg\",roi)\n",
    "            l+=1\n",
    "            print(l,end=' ')\n",
    "            #cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    except:\n",
    "        print(img_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from numpy import asarray\n",
    "from random import randint\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_dataset_path = \"C:/Users/amb/Downloads/face recog project/pics/messi\"\n",
    "person_dataset_path_output=\"dataset_crop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "def extract_face(path_to_filename, detector, required_size=(224,224), save_face=True):\n",
    "    \n",
    "    # print('extrct face from: ',filename,'\\n')\n",
    "    # load image from file\n",
    "    image = Image.open(path_to_filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector, using default weights\n",
    "\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    # bug fix\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    if save_face:\n",
    "        # os.path.split(os.path.abspath(path_to_filename))[0]\n",
    "        file_name = os.path.split(os.path.split(os.path.abspath(path_to_filename))[0])[1]\n",
    "        person_name = os.path.split(os.path.abspath(path_to_filename))[1]\n",
    "        # person_name = os.path.basename(os.path.normpath(path(path)))\n",
    "        # project_folder = os.path.split(path_to_filename)\n",
    "        # project_folder = path(path).parent.parent\n",
    "        print(person_name)\n",
    "        target_folder = os.path.join(person_dataset_path_output, 'face_min', file_name)\n",
    "        if not os.path.exists(target_folder):\n",
    "            os.makedirs(target_folder)\n",
    "        target_face_file_path = os.path.join(target_folder, person_name)\n",
    "        print(target_face_file_path)\n",
    "        image.save(target_face_file_path)\n",
    "    face_array = asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and extract faces for all images in a directory\n",
    "def extract_faces(directory):\n",
    "    print('load faces')\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    # detector=MTCNN()\n",
    "    print('Extracting faces from', directory, '...')\n",
    "    for filename in listdir(directory):\n",
    "        path = directory + filename\n",
    "\n",
    "        # get face\n",
    "        face = extract_face(path, detector, save_face=True)\n",
    "        # store\n",
    "        faces.append(face)\n",
    "        # print(time.time()-tick)\n",
    "    return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def generate_face_from_images(directory):\n",
    "    print('Load dataset...')\n",
    "    X, y = list(), list()\n",
    "\n",
    "    num = 1\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in listdir(directory):\n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = extract_faces(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "\n",
    "        # summarize progress\n",
    "        print('> %d)loaded %d examples for class: %s' % (num, len(faces), subdir))\n",
    "        num += 1\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset...\n",
      "(0,) (0,)\n"
     ]
    }
   ],
   "source": [
    "faces, labels = generate_face_from_images(person_dataset_path)\n",
    "print(faces.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8daeb550ed5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset_download//'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'//*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcascade\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'haarcascade_frontalface_default.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files=glob.glob('dataset_download//'+name+'//*.jpg')\n",
    "cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "l=0\n",
    "for p,file in enumerate(files):\n",
    "    img=cv2.imread(file)\n",
    "    img_g=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=cascade.detectMultiScale(img_g,1.1,3)\n",
    "    for i,face in enumerate(faces):\n",
    "        x,y,w,h=face\n",
    "        print(l)\n",
    "        l+=1\n",
    "        roi=img[y:y+h,x:x+w]\n",
    "        cv2.imwrite('dataset_crop//'+name+'//'+str(p)+'.'+str(i)+'.jpg',roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect my_data_and_crop faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\amb\\\\Downloads\\\\dataset_download'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "files=glob.glob('ttt//*.jpg')\n",
    "cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "name='Wink'\n",
    "try:\n",
    "    os.mkdir('faces dataset//'+name)\n",
    "except:\n",
    "    pass\n",
    "l=0\n",
    "for p,file in enumerate(files):\n",
    "    try:\n",
    "        img=cv2.imread(file)\n",
    "        img_g=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces=cascade.detectMultiScale(img_g,1.1,5)\n",
    "        for i,face in enumerate(faces):\n",
    "            x,y,w,h=face\n",
    "            print(l,end=' ')\n",
    "            l+=1\n",
    "            roi=img[y:y+h,x:x+w]\n",
    "            cv2.imwrite('faces dataset//'+name+'//'+str(p)+'.'+str(i)+'.jpg',roi)\n",
    "    except:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('my pics//صوري//1656387_743490115727719_2508017202103300537_n8989.jpg')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\amb\\\\Downloads\\\\dataset_download'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
